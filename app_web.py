import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from streamlit_drawable_canvas import st_canvas
import cv2
import io
import os
import zipfile
import shutil
from PIL import Image
from scipy.signal import find_peaks

# ================= 1. åŸºç¡€é…ç½® =================
st.set_page_config(page_title="å¾®ç²’å…¨èƒ½åˆ†æå¹³å°", layout="wide", page_icon="ğŸ”¬")

# å…ƒç´ ç‰¹å¾èƒ½é‡è¡¨
ELEMENT_ENERGIES = {
    'C': 0.277, 'N': 0.392, 'O': 0.525, 'Na': 1.041, 'Mg': 1.253, 
    'Al': 1.486, 'Si': 1.739, 'S': 2.307, 'Cl': 2.621, 'K': 3.312, 
    'Ca': 3.690, 'Fe': 6.398, 'Cu': 8.040, 'Zn': 8.630, 'Au': 2.120
}

# ================= 2. æ ¸å¿ƒå¤„ç†å‡½æ•° =================

def align_images(data_map):
    """å¼ºåˆ¶å¯¹é½å›¾åƒå°ºå¯¸ï¼Œé˜²æ­¢æŠ¥é”™"""
    if not data_map: return data_map
    max_h, max_w = 0, 0
    # 1. æ‰¾æœ€å¤§å°ºå¯¸
    for mat in data_map.values():
        h, w = mat.shape
        if h * w > max_h * max_w: max_h, max_w = h, w
    
    # 2. ç»Ÿä¸€ç¼©æ”¾
    aligned = {}
    for k, v in data_map.items():
        if v.shape != (max_h, max_w):
            aligned[k] = cv2.resize(v, (max_w, max_h), interpolation=cv2.INTER_LINEAR)
        else:
            aligned[k] = v
    return aligned

def parse_filename(fname):
    """ä»æ–‡ä»¶åæå–å…ƒç´ å"""
    # ç§»é™¤æ‰©å±•å
    name = fname.rsplit('.', 1)[0]
    # å¤„ç† "Si KÎ±1" æˆ– "01_Si"
    if "ç”µå­å›¾åƒ" in name: return "SE"
    parts = name.replace("_", " ").split(" ")
    # å€’åºæŸ¥æ‰¾ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªåœ¨å…ƒç´ è¡¨é‡Œçš„è¯ï¼Œæˆ–è€…ç›´æ¥ç”¨ç¬¬ä¸€ä¸ªè¯
    for p in reversed(parts):
        if p in ELEMENT_ENERGIES: return p
    return parts[0] # å…œåº•

def read_file_content(file_obj, filename):
    """è¯»å–å•ä¸ªæ–‡ä»¶å†…å®¹è¿”å›çŸ©é˜µæˆ–èƒ½è°±"""
    res_type = None # 'map' or 'spec'
    content = None
    
    if filename.lower().endswith(('.csv')):
        df = pd.read_csv(file_obj, header=None)
        content = df.apply(pd.to_numeric, errors='coerce').fillna(0).values
        res_type = 'map'
        
    elif filename.lower().endswith(('.xls', '.xlsx')):
        # Excel ç‰¹æ®Šå¤„ç†ï¼Œè¿”å›å­—å…¸
        xls = pd.ExcelFile(file_obj)
        content = {}
        for sheet in xls.sheet_names:
            df = pd.read_excel(xls, sheet_name=sheet, header=None)
            content[sheet] = df.apply(pd.to_numeric, errors='coerce').fillna(0).values
        res_type = 'excel_map'
        
    elif filename.lower().endswith('.txt'):
        # èƒ½è°±
        try:
            # å¦‚æœæ˜¯ bytes (ZipExtFile) éœ€è¦ decodeï¼Œå¦‚æœæ˜¯ StringIO (UploadedFile) ä¸éœ€è¦
            if isinstance(file_obj, io.StringIO): 
                text = file_obj.getvalue()
            elif hasattr(file_obj, 'read'):
                text = file_obj.read().decode('utf-8', errors='ignore')
            else:
                text = str(file_obj)
                
            lines = text.splitlines()
            x, y = [], []
            is_data = False
            for line in lines:
                if "SPECTRUM" in line: is_data = True; continue
                if is_data and "," in line:
                    parts = line.strip().split(",")
                    x.append(float(parts[0]))
                    y.append(float(parts[1]))
            content = {'x': x, 'y': y}
            res_type = 'spec'
        except: pass
        
    return res_type, content

# --- æ¨¡å¼ A: å•å¾®ç²’è§£æå™¨ ---
def parse_single_mode(uploaded_files):
    data_map = {}
    spec = {'x': [], 'y': []}
    
    for f in uploaded_files:
        res_type, content = read_file_content(f, f.name)
        
        if res_type == 'map':
            el = parse_filename(f.name)
            data_map[el] = content
        elif res_type == 'excel_map':
            for sheet_name, mat in content.items():
                data_map[sheet_name] = mat
        elif res_type == 'spec':
            spec = content
            
    return {'Single_Particle': {'data': align_images(data_map), 'spec': spec}}

# --- æ¨¡å¼ B: ZIP æ‰¹é‡è§£æå™¨ ---
def parse_batch_mode(zip_file_obj):
    particles = {}
    temp_dir = "temp_zip_extract"
    if os.path.exists(temp_dir): shutil.rmtree(temp_dir)
    os.makedirs(temp_dir)
    
    try:
        with zipfile.ZipFile(zip_file_obj, "r") as z:
            z.extractall(temp_dir)
    except: return {}

    for root, dirs, files in os.walk(temp_dir):
        valid_files = [f for f in files if f.lower().endswith(('.csv', '.xls', '.xlsx', '.txt'))]
        if valid_files:
            pid = os.path.basename(root)
            if pid == temp_dir: pid = "Root"
            # é¿å…é‡å
            if pid in particles: pid = f"{pid}_{len(particles)}"
            
            particles[pid] = {'data': {}, 'spec': {'x':[], 'y':[]}}
            
            for f in valid_files:
                f_path = os.path.join(root, f)
                with open(f_path, 'rb') as fo: # äºŒè¿›åˆ¶è¯»å–ä¾› pandas è§£æ
                    # é’ˆå¯¹ pandas è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œç›´æ¥ä¼ è·¯å¾„å³å¯
                    if f.lower().endswith('.txt'):
                        res_type, content = read_file_content(fo, f)
                    else:
                        # Pandas read functions work better with paths for local files
                        res_type, content = None, None
                        if f.lower().endswith('.csv'):
                            df = pd.read_csv(f_path, header=None)
                            content = df.apply(pd.to_numeric, errors='coerce').fillna(0).values
                            res_type = 'map'
                        elif f.lower().endswith(('.xls', '.xlsx')):
                            # å¤ç”¨é€»è¾‘
                            with open(f_path, 'rb') as excel_fo:
                                res_type, content = read_file_content(excel_fo, f)

                if res_type == 'map':
                    el = parse_filename(f)
                    particles[pid]['data'][el] = content
                elif res_type == 'excel_map':
                    for sheet, mat in content.items():
                        particles[pid]['data'][sheet] = mat
                elif res_type == 'spec':
                    particles[pid]['spec'] = content
            
            particles[pid]['data'] = align_images(particles[pid]['data'])
            
    # shutil.rmtree(temp_dir) # è°ƒè¯•æ—¶å¯æ³¨é‡Š
    return particles

def auto_identify_peaks(x, y):
    x, y = np.array(x), np.array(y)
    if len(y) == 0: return []
    peaks, _ = find_peaks(y, height=np.max(y)*0.05, distance=20)
    results = []
    for p in peaks:
        energy = x[p]
        best_el = None
        min_diff = 0.06
        for el, e_val in ELEMENT_ENERGIES.items():
            if abs(energy - e_val) < min_diff:
                min_diff = abs(energy - e_val); best_el = el
        if best_el: results.append({'x': energy, 'y': y[p], 'text': best_el})
    return results

# ================= 3. UI å¸ƒå±€ =================

st.title("ğŸ”¬ å¾®ç²’å…¨èƒ½åˆ†æå¹³å°")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“‚ æ•°æ®å¯¼å…¥")
    st.info("æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š\n1. **å•å¾®ç²’**ï¼šç›´æ¥æ‹–å…¥å¤šä¸ª CSV/TXT æ–‡ä»¶ã€‚\n2. **æ‰¹é‡**ï¼šæ‹–å…¥ä¸€ä¸ª ZIP å‹ç¼©åŒ…ï¼ˆåŒ…å«å¤šä¸ªæ–‡ä»¶å¤¹ï¼‰ã€‚")
    
    uploaded_files = st.file_uploader("æ‹–æ‹½æ–‡ä»¶åˆ°è¿™é‡Œ", accept_multiple_files=True)
    
    st.markdown("---")
    st.header("ğŸ¨ äº¤äº’è®¾ç½®")
    zoom = st.slider("ç”»å¸ƒç¼©æ”¾", 0.5, 3.0, 1.5, 0.1)
    threshold = st.slider("èƒŒæ™¯é™å™ª", 0, 50, 2)
    tool = st.selectbox("åœˆé€‰å·¥å…·", ["circle", "rect"], format_func=lambda x: "åœ†å½¢" if x=="circle" else "çŸ©å½¢")

# --- ä¸»é€»è¾‘ ---
particles_db = {}

if uploaded_files:
    # æ™ºèƒ½åˆ¤æ–­æ¨¡å¼
    is_zip = any(f.name.endswith('.zip') for f in uploaded_files)
    
    if is_zip:
        st.success("æ£€æµ‹åˆ° ZIP å‹ç¼©åŒ…ï¼Œå·²åˆ‡æ¢è‡³ **æ‰¹é‡åˆ†ææ¨¡å¼**")
        # æ‰¾åˆ°é‚£ä¸ª zip æ–‡ä»¶
        zip_file = next(f for f in uploaded_files if f.name.endswith('.zip'))
        particles_db = parse_batch_mode(zip_file)
    else:
        st.success("æ£€æµ‹åˆ°æ•£ä¹±æ–‡ä»¶ï¼Œå·²åˆ‡æ¢è‡³ **å•å¾®ç²’æ¨¡å¼**")
        particles_db = parse_single_mode(uploaded_files)

    if not particles_db:
        st.error("æ— æ³•è§£ææ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
    else:
        # --- é€‰æ‹©å¾®ç²’ ---
        p_ids = sorted(list(particles_db.keys()))
        
        # å¦‚æœæ˜¯æ‰¹é‡æ¨¡å¼ï¼Œåœ¨ä¾§è¾¹æ æ˜¾ç¤ºåˆ‡æ¢å™¨
        if len(p_ids) > 1:
            st.sidebar.markdown("---")
            st.sidebar.subheader(f"å¾®ç²’åˆ—è¡¨ ({len(p_ids)})")
            selected_id = st.sidebar.selectbox("é€‰æ‹©å¾®ç²’", p_ids)
        else:
            selected_id = p_ids[0]
            
        current_data = particles_db[selected_id]['data']
        current_spec = particles_db[selected_id]['spec']
        
        st.markdown(f"## ğŸ§ª åˆ†æå¯¹è±¡: `{selected_id}`")
        
        # --- æ¸²æŸ“åˆ†æç•Œé¢ ---
        if not current_data:
            st.warning("è¯¥å¾®ç²’æ²¡æœ‰ Mapping æ•°æ®")
        else:
            c1, c2 = st.columns([1.5, 1])
            
            # 1. å‡†å¤‡åº•å›¾
            shape = next(iter(current_data.values())).shape
            h, w = shape
            base_rgb = np.zeros((h, w, 3))
            
            # åˆæˆé€»è¾‘ Si(R) O(G) C(B)
            legend = []
            colors = {'Si':0, 'O':1, 'C':2}
            for el, idx in colors.items():
                if el in current_data:
                    m = current_data[el].copy()
                    m[m < threshold] = 0
                    if m.max() > 0: base_rgb[:,:,idx] = m / m.max()
                    legend.append(f"{el}")
            
            bg_uint8 = (np.clip(base_rgb * 1.5, 0, 1) * 255).astype(np.uint8)
            
            # 2. ç”»å¸ƒåŒºåŸŸ
            with c1:
                cw, ch = int(w*zoom), int(h*zoom)
                bg_pil = Image.fromarray(bg_uint8).resize((cw, ch))
                
                st.caption(f"åˆæˆé¢„è§ˆ ({', '.join(legend)}) - å°ºå¯¸ {cw}x{ch}")
                canvas = st_canvas(
                    fill_color="rgba(255, 165, 0, 0.2)",
                    stroke_width=2,
                    stroke_color="#fff",
                    background_image=bg_pil,
                    height=ch, width=cw,
                    drawing_mode=tool,
                    key=f"cv_{selected_id}_{zoom}" # IDå˜äº†ç”»å¸ƒè‡ªåŠ¨é‡ç½®
                )
                
            # 3. ç»Ÿè®¡ç»“æœ
            with c2:
                if canvas.json_data and canvas.json_data["objects"]:
                    st.subheader("ğŸ“Š å±€éƒ¨é€‰åŒºæˆåˆ†")
                    obj = canvas.json_data["objects"][-1]
                    
                    # ç”ŸæˆMask
                    mask = np.zeros((h, w), dtype=np.uint8)
                    scale = zoom
                    if obj["type"] == "circle":
                        cx, cy = int((obj["left"]+obj["radius"])/scale), int((obj["top"]+obj["radius"])/scale)
                        r = int(obj["radius"]/scale)
                        cv2.circle(mask, (cx, cy), r, 1, -1)
                    elif obj["type"] == "rect":
                        x, y = int(obj["left"]/scale), int(obj["top"]/scale)
                        wb, hb = int(obj["width"]/scale), int(obj["height"]/scale)
                        cv2.rectangle(mask, (x, y), (x+wb, y+hb), 1, -1)
                        
                    # ç»Ÿè®¡
                    stats = {}
                    for el, mat in current_data.items():
                        if el != "SE": stats[el] = np.sum(mat * mask)
                    
                    tot = sum(stats.values()) + 1e-9
                    df = pd.DataFrame({"El": stats.keys(), "Val": stats.values()})
                    df["Pct"] = df["Val"] / tot
                    df = df[df["Pct"] > 0.01].sort_values("Pct", ascending=False)
                    
                    st.plotly_chart(go.Figure(data=[go.Pie(labels=df["El"], values=df["Pct"], hole=0.4)]), use_container_width=True)
                    
                    dia = np.sqrt(4 * np.sum(mask) / np.pi) * 0.05
                    st.metric("ç­‰æ•ˆç›´å¾„", f"{dia:.2f} Î¼m")
                else:
                    st.info("ğŸ‘ˆ è¯·åœ¨å·¦å›¾è¿›è¡Œåœˆé€‰åˆ†æ")
                    
            # 4. èƒ½è°±
            st.markdown("---")
            if current_spec['x']:
                st.subheader("ğŸ“ˆ èƒ½è°±åˆ†æ")
                peaks = auto_identify_peaks(current_spec['x'], current_spec['y'])
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=current_spec['x'], y=current_spec['y'], fill='tozeroy', line=dict(color='#333')))
                for p in peaks:
                    fig.add_annotation(x=p['x'], y=p['y'], text=p['text'], showarrow=True, arrowhead=2, ay=-30)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.caption("æ— èƒ½è°±æ•°æ®")
                
            # 5. å›¾é›†
            with st.expander("æŸ¥çœ‹å…¨éƒ¨åˆ†å›¾"):
                cols = st.columns(6)
                for i, (el, mat) in enumerate(current_data.items()):
                    with cols[i%6]:
                        st.image(mat/(mat.max()+1e-6), caption=el)

else:
    st.info("ğŸ‘‹ ç­‰å¾…æ•°æ®ä¸Šä¼ ...")
