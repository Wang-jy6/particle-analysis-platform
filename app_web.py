import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from streamlit_drawable_canvas import st_canvas
import cv2
import io
import os
import zipfile
import shutil
from PIL import Image
from scipy.signal import find_peaks

# ================= 1. å…¨å±€é…ç½® =================
st.set_page_config(page_title="å¾®ç²’å…¨èƒ½åˆ†æå¹³å°", layout="wide", page_icon="ğŸ”¬")

# å¸¸è§å…ƒç´ ç‰¹å¾èƒ½é‡è¡¨ (keV) - ç”¨äºè‡ªåŠ¨æ ‡å³°
ELEMENT_ENERGIES = {
    'C': 0.277, 'N': 0.392, 'O': 0.525, 'F': 0.677,
    'Na': 1.041, 'Mg': 1.253, 'Al': 1.486, 'Si': 1.739,
    'P': 2.013, 'S': 2.307, 'Cl': 2.621, 'K': 3.312, 
    'Ca': 3.690, 'Ti': 4.508, 'Cr': 5.411, 'Mn': 5.894,
    'Fe': 6.398, 'Ni': 7.471, 'Cu': 8.040, 'Zn': 8.630, 
    'Au': 2.120, 'Ag': 2.980, 'Ba': 4.465
}

# ================= 2. æ ¸å¿ƒå¤„ç†é€»è¾‘ =================

def align_images(data_map):
    """
    å¼ºåˆ¶å¯¹é½æ‰€æœ‰å›¾åƒå°ºå¯¸ï¼Œè§£å†³ SE å›¾ä¸ Mapping å›¾åˆ†è¾¨ç‡ä¸ä¸€è‡´å¯¼è‡´çš„ ValueError
    """
    if not data_map: return data_map
    
    # 1. å¯»æ‰¾æœ€å¤§å°ºå¯¸
    max_h, max_w = 0, 0
    for mat in data_map.values():
        h, w = mat.shape
        if h * w > max_h * max_w:
            max_h, max_w = h, w
    
    # 2. ç»Ÿä¸€ç¼©æ”¾åˆ°æœ€å¤§å°ºå¯¸
    aligned = {}
    for k, v in data_map.items():
        if v.shape != (max_h, max_w):
            # æ³¨æ„ cv2.resize æ¥å— (width, height)
            aligned[k] = cv2.resize(v, (max_w, max_h), interpolation=cv2.INTER_LINEAR)
        else:
            aligned[k] = v
    return aligned

def parse_element_name(filename):
    """
    æ™ºèƒ½è§£ææ–‡ä»¶åä¸­çš„å…ƒç´ å
    ä¾‹å¦‚: "Si KÎ±1.csv" -> "Si", "01_Fe.xls" -> "Fe"
    """
    # ç§»é™¤åç¼€
    name = filename.rsplit('.', 1)[0]
    
    # ç‰¹æ®Šæ ‡è®°
    if "ç”µå­å›¾åƒ" in name or "SE" in name.upper(): 
        return "SE"
    
    # åˆ†å‰²å­—ç¬¦ä¸²ï¼Œå¯»æ‰¾å…ƒç´ è¡¨ä¸­çš„å…³é”®å­—
    parts = name.replace("_", " ").split(" ")
    # ä¼˜å…ˆåŒ¹é…æœ«å°¾çš„è¯ï¼ˆé€šå¸¸å…ƒç´ ååœ¨æœ€åï¼‰
    for p in reversed(parts):
        # å»é™¤å¯èƒ½é™„å¸¦çš„æ•°å­—æˆ–ç¬¦å·
        clean_p = ''.join(filter(str.isalpha, p)) 
        if clean_p in ELEMENT_ENERGIES:
            return clean_p
            
    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªè¯ä½œä¸ºé»˜è®¤
    return parts[0]

def read_file_content(file_obj, filename):
    """
    ç»Ÿä¸€è¯»å–å™¨ï¼šæ”¯æŒ CSV, Excel, TXT
    è¿”å›: type ('map'/'spec'/'excel_map'), content
    """
    res_type = None
    content = None
    
    fname_lower = filename.lower()
    
    try:
        if fname_lower.endswith('.csv'):
            df = pd.read_csv(file_obj, header=None)
            content = df.apply(pd.to_numeric, errors='coerce').fillna(0).values
            res_type = 'map'
            
        elif fname_lower.endswith(('.xls', '.xlsx')):
            xls = pd.ExcelFile(file_obj)
            content = {}
            for sheet in xls.sheet_names:
                df = pd.read_excel(xls, sheet_name=sheet, header=None)
                mat = df.apply(pd.to_numeric, errors='coerce').fillna(0).values
                content[sheet] = mat
            res_type = 'excel_map'
            
        elif fname_lower.endswith('.txt'):
            # å¤„ç†ç¼–ç å’Œè¯»å–æ–¹å¼å·®å¼‚
            if isinstance(file_obj, io.StringIO):
                text = file_obj.getvalue()
            elif hasattr(file_obj, 'read'):
                # äºŒè¿›åˆ¶æµéœ€è¦è§£ç 
                text = file_obj.read().decode('utf-8', errors='ignore')
            else:
                text = str(file_obj)
                
            lines = text.splitlines()
            x, y = [], []
            is_data = False
            for line in lines:
                if "SPECTRUM" in line: is_data = True; continue
                if is_data and "," in line:
                    parts = line.strip().split(",")
                    if len(parts) >= 2:
                        x.append(float(parts[0]))
                        y.append(float(parts[1]))
            content = {'x': x, 'y': y}
            res_type = 'spec'
            
    except Exception as e:
        # è¿™é‡Œçš„ print åªæœ‰åœ¨åå°ç»ˆç«¯èƒ½çœ‹åˆ°ï¼Œç½‘é¡µä¸Šä¸ä¼šæŠ¥é”™ä¸­æ–­
        print(f"Error reading {filename}: {e}")
        pass
        
    return res_type, content

def auto_identify_peaks(x, y):
    """èƒ½è°±è‡ªåŠ¨æ‰¾å³°"""
    x, y = np.array(x), np.array(y)
    if len(y) == 0: return []
    
    # å¯»æ‰¾æ³¢å³°ï¼Œé«˜åº¦è‡³å°‘ä¸ºæœ€å¤§å€¼çš„ 5%
    peaks, _ = find_peaks(y, height=np.max(y)*0.05, distance=15)
    
    results = []
    found_elements = set()
    
    for p in peaks:
        energy = x[p]
        peak_height = y[p]
        
        best_el = None
        min_diff = 0.05 # å®¹å·® 50eV
        
        for el, e_val in ELEMENT_ENERGIES.items():
            if abs(energy - e_val) < min_diff:
                min_diff = abs(energy - e_val)
                best_el = el
        
        if best_el and best_el not in found_elements:
            results.append({'x': energy, 'y': peak_height, 'text': best_el})
            # ç®€å•çš„é˜²é‡æœºåˆ¶ï¼Œé˜²æ­¢ç›¸è¿‘å³°æ ‡ä¸¤é (å¯é€‰)
            # found_elements.add(best_el) 
            
    return results

# --- æ¨¡å¼ A: å•å¾®ç²’ (ç›´æ¥è§£æ UploadedFile åˆ—è¡¨) ---
def parse_single_mode(uploaded_files):
    data_map = {}
    spec = {'x': [], 'y': []}
    
    for f in uploaded_files:
        # é‡ç½®æŒ‡é’ˆï¼Œé˜²æ­¢è¯»å–ç©ºå†…å®¹
        f.seek(0)
        res_type, content = read_file_content(f, f.name)
        
        if res_type == 'map':
            el = parse_element_name(f.name)
            data_map[el] = content
        elif res_type == 'excel_map':
            # Excel å¯èƒ½åŒ…å«å¤šä¸ª Sheet (å¤šä¸ªå…ƒç´ )
            for sheet_name, mat in content.items():
                data_map[sheet_name] = mat
        elif res_type == 'spec':
            spec = content
            
    # å¯¹é½å¹¶è¿”å›ç»“æ„
    return {'Single_Particle': {'data': align_images(data_map), 'spec': spec}}

# --- æ¨¡å¼ B: ZIP æ‰¹é‡ (è§£å‹åéå†) ---
def parse_batch_mode(zip_file_obj):
    particles = {}
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = "temp_zip_extract"
    if os.path.exists(temp_dir): shutil.rmtree(temp_dir)
    os.makedirs(temp_dir)
    
    try:
        with zipfile.ZipFile(zip_file_obj, "r") as z:
            z.extractall(temp_dir)
    except:
        return {}
        
    # éå†ç›®å½•ç»“æ„
    for root, dirs, files in os.walk(temp_dir):
        # ç­›é€‰æœ‰æ•ˆæ–‡ä»¶
        valid_files = [f for f in files if f.lower().endswith(('.csv', '.xls', '.xlsx', '.txt'))]
        
        if valid_files:
            # ä»¥å‰ä¸€æ–‡ä»¶å¤¹åä½œä¸ºå¾®ç²’ ID
            pid = os.path.basename(root)
            if pid == temp_dir: pid = "Root_Folder"
            if pid in particles: pid = f"{pid}_{len(particles)}" # é˜²é‡å
            
            particles[pid] = {'data': {}, 'spec': {'x':[], 'y':[]}}
            
            for f in valid_files:
                f_path = os.path.join(root, f)
                with open(f_path, 'rb') as fo:
                    res_type, content = read_file_content(fo, f)
                    
                    if res_type == 'map':
                        el = parse_element_name(f)
                        particles[pid]['data'][el] = content
                    elif res_type == 'excel_map':
                        for sheet, mat in content.items():
                            particles[pid]['data'][sheet] = mat
                    elif res_type == 'spec':
                        particles[pid]['spec'] = content
            
            # å¯¹é½è¯¥å¾®ç²’çš„æ‰€æœ‰å›¾åƒ
            particles[pid]['data'] = align_images(particles[pid]['data'])
            
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ (å»ºè®®åœ¨ Web æœåŠ¡ä¸­å¯ç”¨ï¼Œé˜²æ­¢ç£ç›˜å æ»¡)
    # shutil.rmtree(temp_dir)
    return particles

# ================= 3. ç”¨æˆ·ç•Œé¢ (UI) =================

st.title("ğŸ”¬ å¾®ç²’å…¨èƒ½åˆ†æå¹³å°")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“‚ æ•°æ®å¯¼å…¥")
    st.info("""
    **æ™ºèƒ½åŒæ¨¡å¼ï¼š**
    1. **å•å¾®ç²’**ï¼šç›´æ¥æ‹–å…¥å¤šä¸ª .csv/.xlsx/.txt æ–‡ä»¶ã€‚
    2. **æ‰¹é‡**ï¼šæ‹–å…¥ä¸€ä¸ª .zip å‹ç¼©åŒ…ï¼ˆå†…å«å¤šä¸ªå¾®ç²’æ–‡ä»¶å¤¹ï¼‰ã€‚
    """)
    uploaded_files = st.file_uploader("è¯·ä¸Šä¼ æ–‡ä»¶", accept_multiple_files=True)
    
    st.markdown("---")
    st.header("ğŸ¨ äº¤äº’è®¾ç½®")
    zoom_level = st.slider("ç”»å¸ƒç¼©æ”¾ (Zoom)", 0.5, 4.0, 1.5, 0.1)
    bg_threshold = st.slider("èƒŒæ™¯é™å™ª (Threshold)", 0, 50, 2)
    draw_mode = st.selectbox("åœˆé€‰å·¥å…·", ["circle", "rect"], format_func=lambda x: "åœ†å½¢" if x=="circle" else "çŸ©å½¢")

# --- ä¸»é€»è¾‘åŒº ---
particles_db = {}

if uploaded_files:
    # 1. æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼Œå†³å®šæ¨¡å¼
    is_zip = any(f.name.lower().endswith('.zip') for f in uploaded_files)
    
    if is_zip:
        # æ‰¹é‡æ¨¡å¼ï¼šåªå¤„ç†ç¬¬ä¸€ä¸ª zip
        zip_file = next(f for f in uploaded_files if f.name.lower().endswith('.zip'))
        with st.spinner(f"æ­£åœ¨è§£å‹åˆ†æ {zip_file.name}..."):
            particles_db = parse_batch_mode(zip_file)
        if particles_db:
            st.success(f"ğŸ“¦ å·²åˆ‡æ¢è‡³æ‰¹é‡æ¨¡å¼ï¼Œæ£€æµ‹åˆ° {len(particles_db)} ä¸ªå¾®ç²’")
    else:
        # å•å¾®ç²’æ¨¡å¼
        particles_db = parse_single_mode(uploaded_files)
        if particles_db:
            st.success("ğŸ“„ å·²åˆ‡æ¢è‡³å•å¾®ç²’æ¨¡å¼")

    if not particles_db:
        st.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼ã€‚")
        
    else:
        # 2. å¾®ç²’é€‰æ‹©å™¨
        p_ids = sorted(list(particles_db.keys()))
        selected_pid = p_ids[0]
        
        # å¦‚æœå¾®ç²’æ•°é‡å¤§äº1ï¼Œæ˜¾ç¤ºé€‰æ‹©æ¡†
        if len(p_ids) > 1:
            st.sidebar.markdown("---")
            st.sidebar.subheader(f"é€‰æ‹©å¾®ç²’ ({len(p_ids)})")
            selected_pid = st.sidebar.selectbox("å½“å‰åˆ†æå¯¹è±¡:", p_ids)
            
        # è·å–å½“å‰æ•°æ®
        current_data = particles_db[selected_pid]['data']
        current_spec = particles_db[selected_pid]['spec']
        
        st.markdown(f"### ğŸ§ª å½“å‰åˆ†æ: `{selected_pid}`")
        
        # 3. æ¸²æŸ“åˆ†æåŒº
        if not current_data:
            st.error("è¯¥å¾®ç²’æ²¡æœ‰æœ‰æ•ˆçš„å…ƒç´ åˆ†å¸ƒå›¾ (Mapping) æ•°æ®ã€‚")
        else:
            col_canvas, col_result = st.columns([1.5, 1])
            
            # --- A. å›¾åƒåˆæˆä¸ç”»å¸ƒ ---
            # è·å–å°ºå¯¸
            shape = next(iter(current_data.values())).shape
            h, w = shape
            
            # åŠ¨æ€åˆæˆåº•å›¾ (é»˜è®¤æ˜¾ç¤º Si, O, C)
            base_rgb = np.zeros((h, w, 3))
            colors = {'Si': 0, 'O': 1, 'C': 2} # R, G, B
            legend = []
            
            for el, ch_idx in colors.items():
                if el in current_data:
                    mat = current_data[el].copy()
                    # ç®€å•é™å™ª
                    mat[mat < bg_threshold] = 0
                    # å½’ä¸€åŒ–
                    if mat.max() > 0:
                        base_rgb[:, :, ch_idx] = mat / mat.max()
                    legend.append(f"{el}")
            
            # å¢å¼ºäº®åº¦å¹¶è½¬ä¸º 8-bit å›¾ç‰‡
            bg_uint8 = (np.clip(base_rgb * 1.5, 0, 1) * 255).astype(np.uint8)
            
            with col_canvas:
                # è®¡ç®—ç¼©æ”¾åçš„ç”»å¸ƒå°ºå¯¸
                cw, ch = int(w * zoom_level), int(h * zoom_level)
                
                # å°† numpy array è½¬ä¸º PIL Image ä»¥ä¾›ç”»å¸ƒèƒŒæ™¯ä½¿ç”¨
                bg_pil = Image.fromarray(bg_uint8).resize((cw, ch))
                
                st.caption(f"åˆæˆè§†å›¾ ({', '.join(legend)}) - å°ºå¯¸: {w}x{h} -> {cw}x{ch}")
                
                # äº¤äº’å¼ç”»å¸ƒ
                canvas_result = st_canvas(
                    fill_color="rgba(255, 165, 0, 0.2)",  # åŠé€æ˜æ©™è‰²å¡«å……
                    stroke_width=2,
                    stroke_color="#ffffff",
                    background_image=bg_pil,
                    update_streamlit=True,
                    height=ch,
                    width=cw,
                    drawing_mode=draw_mode,
                    key=f"canvas_{selected_pid}_{zoom_level}", # IDå˜åŒ–æ—¶é‡ç½®ç”»å¸ƒ
                )
                
            # --- B. é€‰åŒºç»Ÿè®¡ç»“æœ ---
            with col_result:
                if canvas_result.json_data and canvas_result.json_data["objects"]:
                    st.subheader("ğŸ“Š é€‰åŒºæˆåˆ†åˆ†æ")
                    obj = canvas_result.json_data["objects"][-1]
                    
                    # åˆ›å»º Mask (éœ€è¦è¿˜åŸç¼©æ”¾æ¯”ä¾‹)
                    mask = np.zeros((h, w), dtype=np.uint8)
                    scale = zoom_level
                    
                    if obj["type"] == "circle":
                        cx = int((obj["left"] + obj["radius"]) / scale)
                        cy = int((obj["top"] + obj["radius"]) / scale)
                        r = int(obj["radius"] / scale)
                        cv2.circle(mask, (cx, cy), r, 1, -1)
                        
                    elif obj["type"] == "rect":
                        x = int(obj["left"] / scale)
                        y = int(obj["top"] / scale)
                        wb = int(obj["width"] / scale)
                        hb = int(obj["height"] / scale)
                        cv2.rectangle(mask, (x, y), (x + wb, y + hb), 1, -1)
                    
                    # è®¡ç®—é€‰åŒºå†…çš„å…ƒç´ æ€»é‡
                    stats = {}
                    for el, mat in current_data.items():
                        if el == "SE": continue # è·³è¿‡ç”µå­å›¾åƒ
                        stats[el] = np.sum(mat * mask)
                    
                    # å½’ä¸€åŒ–å¹¶ç»˜å›¾
                    total_intensity = sum(stats.values()) + 1e-9
                    df_res = pd.DataFrame({"Element": stats.keys(), "Intensity": stats.values()})
                    df_res["Percentage"] = df_res["Intensity"] / total_intensity
                    # åªæ˜¾ç¤ºå æ¯” > 1% çš„å…ƒç´ 
                    df_res = df_res[df_res["Percentage"] > 0.01].sort_values("Percentage", ascending=False)
                    
                    st.plotly_chart(go.Figure(data=[go.Pie(
                        labels=df_res["Element"], 
                        values=df_res["Percentage"],
                        hole=0.4
                    )]), use_container_width=True)
                    
                    # ä¼°ç®—ç²’å¾„ (å‡è®¾ 0.05 um/pixel)
                    pixel_area = np.sum(mask)
                    est_diameter = np.sqrt(4 * pixel_area / np.pi) * 0.05
                    st.metric("é€‰åŒºç­‰æ•ˆç›´å¾„", f"{est_diameter:.2f} Î¼m")
                    
                else:
                    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§å›¾åƒä¸Šç”»åœˆï¼ŒæŸ¥çœ‹å±€éƒ¨æˆåˆ†å æ¯”ã€‚")
                    
            # --- C. èƒ½è°±åˆ†æ ---
            st.markdown("---")
            if current_spec['x']:
                st.subheader("ğŸ“ˆ EDS èƒ½è°± (è‡ªåŠ¨æ ‡å³°)")
                
                # è‡ªåŠ¨æ‰¾å³°
                peaks = auto_identify_peaks(current_spec['x'], current_spec['y'])
                
                fig = go.Figure()
                # ç»˜åˆ¶æ³¢å½¢
                fig.add_trace(go.Scatter(
                    x=current_spec['x'], y=current_spec['y'],
                    mode='lines', fill='tozeroy', line=dict(color='#444'), name='Spectrum'
                ))
                # æ·»åŠ æ ‡æ³¨
                for p in peaks:
                    fig.add_annotation(
                        x=p['x'], y=p['y'],
                        text=p['text'],
                        showarrow=True, arrowhead=2, ay=-30
                    )
                
                fig.update_layout(
                    xaxis_title="Energy (keV)", 
                    yaxis_title="Counts",
                    height=400,
                    hovermode="x unified"
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.caption("è¯¥å¾®ç²’æœªæ£€æµ‹åˆ°èƒ½è°± (.txt) æ•°æ®")
                
            # --- D. å›¾é›†æ¦‚è§ˆ ---
            with st.expander("æŸ¥çœ‹æ‰€æœ‰å…ƒç´ åˆ†å›¾ (ç‚¹å‡»å±•å¼€)"):
                # è·å–æ‰€æœ‰å…ƒç´ åå¹¶æ’åº
                elements = sorted(current_data.keys())
                cols = st.columns(6) # æ¯è¡Œ6ä¸ª
                for i, el in enumerate(elements):
                    with cols[i % 6]:
                        # æ˜¾ç¤ºç¼©ç•¥å›¾ (å½’ä¸€åŒ–)
                        mat = current_data[el]
                        norm_mat = mat / (mat.max() + 1e-6)
                        st.image(norm_mat, caption=el, use_container_width=True)

else:
    # å¼•å¯¼é¡µ
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨å¾®ç²’åˆ†æå¹³å°ï¼è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ•°æ®å¼€å§‹ã€‚")
